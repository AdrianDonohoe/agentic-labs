{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5897097",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andrew\\Documents\\dkit-projects\\agentic\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# import HumanMessages for the LLM invocation\n",
    "from langchain.messages import HumanMessage, SystemMessage\n",
    "# import checkpointer\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "from langchain.messages import AnyMessage, RemoveMessage\n",
    "\n",
    "from langgraph.prebuilt import ToolNode, InjectedState\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain_community.tools.file_management.read import ReadFileTool\n",
    "\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.types import interrupt, Command\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "import sqlite3\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93519eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "reflection_llm = ChatGoogleGenerativeAI(\n",
    "    model=os.getenv(\"GOOGLE_API_MODEL\"),\n",
    "    temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f81fc864",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(\n",
    "    # model=\"granite4:350m\",\n",
    "    # model=\"qwen3:4b\",\n",
    "    model=\"granite4:latest\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99d2a88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "DB_FILE = 'music.db'\n",
    "\n",
    "@tool\n",
    "def get_album_by_title(title):\n",
    "    \"\"\"\n",
    "    Returns the album with the given title.\n",
    "\n",
    "    Args:\n",
    "        title (str): Title of the album to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Album data (number, year, album, artist, genre, subgenre, price)\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(DB_FILE)\n",
    "    c = conn.cursor()\n",
    "    query = \"SELECT * FROM music WHERE album = ?\"\n",
    "    c.execute(query, (title,))\n",
    "    result = c.fetchone()\n",
    "    conn.close()\n",
    "    return result\n",
    "\n",
    "@tool\n",
    "def get_albums_by_artist(artist):\n",
    "    \"\"\"\n",
    "    Returns all albums by the given artist.\n",
    "\n",
    "    Args:\n",
    "        artist (str): Artist name to retrieve albums for.\n",
    "\n",
    "    Returns:\n",
    "        list: List of album data (number, year, album, artist, genre, subgenre, price)\n",
    "    \"\"\"\n",
    "    print(\"DEBUG: get_albums_by_artist\", artist)\n",
    "    conn = sqlite3.connect(DB_FILE)\n",
    "    c = conn.cursor()\n",
    "    query = \"SELECT * FROM music WHERE artist = ?\"\n",
    "    c.execute(query, (artist,))\n",
    "    results = c.fetchall()\n",
    "    conn.close()\n",
    "    return results\n",
    "\n",
    "@tool\n",
    "def get_albums_by_year(year):\n",
    "    \"\"\"\n",
    "    Returns all albums released in the given year.\n",
    "\n",
    "    Args:\n",
    "        year (int): Year to retrieve albums for.\n",
    "\n",
    "    Returns:\n",
    "        list: List of album data (number, year, album, artist, genre, subgenre, price)\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(DB_FILE)\n",
    "    c = conn.cursor()\n",
    "    query = \"SELECT * FROM music WHERE year = ?\"\n",
    "    c.execute(query, (year,))\n",
    "    results = c.fetchall()\n",
    "    conn.close()\n",
    "    return results\n",
    "\n",
    "@tool\n",
    "def get_albums_by_genre(genre):\n",
    "    \"\"\"\n",
    "    Returns all albums of the given genre.\n",
    "\n",
    "    Args:\n",
    "        genre (str): Genre to retrieve albums for.\n",
    "\n",
    "    Returns:\n",
    "        list: List of album data (number, year, album, artist, genre, subgenre, price)\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(DB_FILE)\n",
    "    c = conn.cursor()\n",
    "    query = \"SELECT * FROM music WHERE genre = ?\"\n",
    "    c.execute(query, (genre,))\n",
    "    results = c.fetchall()\n",
    "    conn.close()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "638e0bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecordShopState(MessagesState):\n",
    "    email: str\n",
    "    success: bool\n",
    "    count: int = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86c8ba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def action(state: RecordShopState) -> dict:\n",
    "    result = llm.bind_tools([get_album_by_title, get_albums_by_artist, get_albums_by_year, get_albums_by_genre]).invoke(state['messages'])\n",
    "    return {\"messages\": result}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b876f53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReflectionResponse(BaseModel):\n",
    "    success: bool = Field(description=\"Indicates whether the previous action was successful.\")\n",
    "    correction_prompt: str = Field(description=\"New improved prompt to help the agent correct its response if success is False.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5aecc0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflection_action(state: RecordShopState) -> dict:\n",
    "    # get last message and reflect on it against specific criteria\n",
    "    last_message = state['messages'][-1].content\n",
    "    system_message = state['messages'][0].content\n",
    "    print(\"RELECTION MODEL CHECKING LAST MESSAGE:\")\n",
    "    reflection_prompt = f\"\"\"\n",
    "    You are reflecting on the output of a music album query system.  The agent has the following PROMPT:\n",
    "<PROMPT>    \n",
    "{system_message}\n",
    "</PROMPT>\n",
    "\n",
    "The customer's email query was:\n",
    "<EMAIL>\n",
    "{state['email']}\n",
    "</EMAIL>\n",
    "\n",
    "\n",
    "The last response from the agent was:\n",
    "<RESPONSE>\n",
    "{last_message}\n",
    "</RESPONSE>\n",
    "\n",
    "\n",
    "If the response does not meet the goal in the prompt WRITE an IMPROVED prompt, different from the original prompt, that would help the agent produce a better response next time.\n",
    "The instructions must concise.  Use bullet points if helpful. \n",
    "\"\"\"\n",
    "    reflection_response = reflection_llm.with_structured_output(ReflectionResponse).invoke([HumanMessage(content=reflection_prompt)])\n",
    "    if reflection_response.success:\n",
    "        return {\"success\": True}\n",
    "    new_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"]] + [SystemMessage(content=reflection_response.correction_prompt)] + [HumanMessage(content=state['email'])]\n",
    "    # new_messages = HumanMessage(content=reflection_response.correction_prompt)\n",
    "    return {\"messages\": new_messages, \"success\": False, \"count\": state['count'] + 1}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b484adb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(RecordShopState)\n",
    "graph.add_node(\"action\", action)\n",
    "graph.add_node(\"tools\", ToolNode([get_album_by_title, get_albums_by_artist, get_albums_by_year, get_albums_by_genre]))\n",
    "graph.add_node(\"reflection\", reflection_action)\n",
    "\n",
    "graph.add_edge(START, \"action\")\n",
    "# conditional edge - if tool_calls == [] for to END else to \"tools\"\n",
    "graph.add_conditional_edges(\"action\", \n",
    "    lambda state: state['messages'][-1].tool_calls == [],\n",
    "    path_map={True: \"reflection\", False: \"tools\"}\n",
    "    )\n",
    "graph.add_edge(\"tools\", \"action\")\n",
    "graph.add_conditional_edges(\"reflection\", lambda state: state['success'] == True or state['count'] > 10, path_map={True: END, False: \"action\"})\n",
    "\n",
    "compiled_graph = graph.compile()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6ea1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37dd40b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_react = \"\"\"\n",
    "You are a helpful assistant in a record shop that sells albums.  \n",
    "You are answering queries from emails about what albums are available or making recommendations.\n",
    "Answer the queries in a friendly and informative way.  If the email includes the customer name please use it. Sign your emails in the name of Andrew.\n",
    "Think step by step and call the tools as needed to get the information required to answer the query.\n",
    "\n",
    "\"\"\"\n",
    "prompt_react = \"\"\"\n",
    "\n",
    "\n",
    "The query is:\n",
    "{query}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef37c008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: get_albums_by_artist David Bowie\n",
      "RELECTION MODEL CHECKING LAST MESSAGE:\n",
      "Hi Tom,\n",
      "\n",
      "Great news! We have several David Bowie albums available in our store. Here are a few highlights:\n",
      "\n",
      "1. **The Rise and Fall of Ziggy Stardust and the Spiders From Mars** (1972) – A classic rock masterpiece that defined his glam persona.\n",
      "2. **Hunky Dory** (1971) – One of his early works showcasing raw talent.\n",
      "3. **Low** (1977) – An experimental electronic/rock fusion album.\n",
      "4. **Aladdin Sane** (1973) – Another powerful glam rock release.\n",
      "5. **Station to Station** (1976) – A blend of rock, funk, and soul.\n",
      "\n",
      "Let me know if you’d like more details on any of these or need help finding a specific one!\n",
      "\n",
      "Cheers,\n",
      "Andrew\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"emails.csv\")\n",
    "for index, row in df.iterrows():\n",
    "    email = row['email']\n",
    "    run = row['run']\n",
    "    if run == \"yes\":\n",
    "        messages = [SystemMessage(content=system_prompt_react),\n",
    "                    HumanMessage(content=prompt_react.format(query=email))]\n",
    "        response = compiled_graph.invoke(input=RecordShopState(messages=messages, success=True, count=0, email=email), config=RunnableConfig(recursion_limit=100))\n",
    "        # response = main_react(email)\n",
    "        df.at[index, 'response'] = response['messages'  ][-1].content\n",
    "        print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4a1f4a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessage(content='Do you have any David Bowie albums available? Cheers Tom', additional_kwargs={}, response_metadata={}, id='a55f3aef-5b4f-4f2f-99f6-514663204db8')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['messages'][-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
