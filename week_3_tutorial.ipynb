{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfda5b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "import os, json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from langsmith.wrappers import wrap_openai\n",
    "from langsmith import traceable\n",
    "from openai import pydantic_function_tool\n",
    "load_dotenv()\n",
    "\n",
    "# read in env variables\n",
    "#api_key = os.getenv(\"OLLAMA_API_KEY\")\n",
    "#api_base = os.getenv(\"OLLAMA_API_BASE\")\n",
    "#model = os.getenv(\"QWEN3_API_MODEL\")\n",
    "\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "api_base = os.getenv(\"GEMINI_API_BASE\")\n",
    "model = os.getenv(\"GEMINI_API_MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8fa27ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gemini-2.5-flash-lite'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9f689d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tool using pydantic BaseModel and Field, which reads a file and returns its contents\n",
    "class ReadFileTool(BaseModel):\n",
    "    \"\"\" Tool that reads a file and returns its contents. \"\"\"\n",
    "    name: str = Field(description=\"The name of the file to read.\")\n",
    "    def run(self) -> str:\n",
    "        try:\n",
    "            with open(self.name, 'r', encoding=\"utf-8\") as file:\n",
    "                return \"####\\n\" + file.read() + \"\\n####\"\n",
    "        except Exception as e:\n",
    "            return str(e)\n",
    "\n",
    "class ReadFileList(BaseModel):\n",
    "    \"\"\" Tool that reads files from a list of file names and returns the contents of all files in the list as a string. \"\"\"\n",
    "    textFiles: list = Field(description=\"The list files to read.\")\n",
    "    def run(self) -> str:\n",
    "        merged_content = \"\"\n",
    "        for file_path in self.textFiles:\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    content = file.read()\n",
    "                    merged_content += content + \"\\n\"  # Add newline between files\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Warning: File '{file_path}' not found. Skipping.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file '{file_path}': {e}\")\n",
    "        \n",
    "        return merged_content.strip()  # Remove trailing newline\n",
    "        \n",
    "class FindTextFiles(BaseModel):\n",
    "    \"\"\" Tool that finds text files in a directory and returns a list of text file names. \"\"\"\n",
    "    dirPath: str = Field(description=\"The path of the directory to read text files from\")\n",
    "    def run(self) -> list:\n",
    "        \"\"\"List various types of text files in the given directory\"\"\"\n",
    "        text_extensions = {'.txt', '.text', '.log', '.md', '.rst', '.csv', '.json', '.xml'}\n",
    "        text_files = []\n",
    "\n",
    "        for file in os.listdir(self.dirPath):\n",
    "            file_path = os.path.join(self.dirPath, file)\n",
    "            if os.path.isfile(file_path):\n",
    "            # Check file extension\n",
    "                _, ext = os.path.splitext(file)\n",
    "                if ext.lower() in text_extensions:\n",
    "                    text_files.append(file)\n",
    "        \n",
    "        return text_files\n",
    "    \n",
    "class FindTextFilesAndMerge(BaseModel):\n",
    "    \"\"\" Tool that finds text files in a directory and returns a string of their merged contents. \"\"\"\n",
    "    dirPath: str = Field(description=\"The path of the directory to read text files from\")\n",
    "    def run(self) -> list:\n",
    "        \"\"\"List various types of text files in the given directory\"\"\"\n",
    "        text_extensions = {'.txt', '.text', '.log', '.md', '.rst', '.csv', '.json', '.xml'}\n",
    "        text_files = []\n",
    "\n",
    "        for file in os.listdir(self.dirPath):\n",
    "            file_path = os.path.join(self.dirPath, file)\n",
    "            if os.path.isfile(file_path):\n",
    "            # Check file extension\n",
    "                _, ext = os.path.splitext(file)\n",
    "                if ext.lower() in text_extensions:\n",
    "                    text_files.append(file)\n",
    "            \n",
    "        merged_content = \"\"\n",
    "        for file_path in text_files:\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    content = file.read()\n",
    "                    merged_content += content + \"\\n\"  # Add newline between files\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Warning: File '{file_path}' not found. Skipping.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file '{file_path}': {e}\")\n",
    "        \n",
    "        return merged_content.strip()  # Remove trailing newline\n",
    "    \n",
    "\n",
    "class FindTextFilesAndMergeSummarise(BaseModel):\n",
    "    \"\"\" Tool that finds text files in a directory and merges their contents and returns a summary of their contents . \"\"\"\n",
    "    dirPath: str = Field(description=\"The path of the directory to read text files from\")\n",
    "    def run(self) -> list:\n",
    "        \"\"\"List various types of text files in the given directory\"\"\"\n",
    "        text_extensions = {'.txt', '.text', '.log', '.md', '.rst', '.csv', '.json', '.xml'}\n",
    "        text_files = []\n",
    "\n",
    "        for file in os.listdir(self.dirPath):\n",
    "            file_path = os.path.join(self.dirPath, file)\n",
    "            if os.path.isfile(file_path):\n",
    "            # Check file extension\n",
    "                _, ext = os.path.splitext(file)\n",
    "                if ext.lower() in text_extensions:\n",
    "                    text_files.append(file)\n",
    "            \n",
    "        merged_content = \"\"\n",
    "        for file_path in text_files:\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    content = file.read()\n",
    "                    merged_content += content + \"\\n\"  # Add newline between files\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Warning: File '{file_path}' not found. Skipping.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file '{file_path}': {e}\")\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a useful assistant that summarises text.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Please summarise the following text: {content}\".format(content=merged_content)}\n",
    "        ]\n",
    "        client = wrap_openai(OpenAI(\n",
    "            api_key=api_key,\n",
    "            base_url=api_base,\n",
    "        ))\n",
    "        response = client.chat.completions.create (\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content\n",
    "        \n",
    "        \n",
    "        #return merged_content.strip()  # Remove trailing newline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52b7c8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = wrap_openai(OpenAI(\n",
    " api_key=api_key,\n",
    " base_url=api_base,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1153fe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(name=\"Summarise Workflow\")\n",
    "def summarise_workflow():\n",
    "\n",
    " # message to read file\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a useful assistant that reads files.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Please open the file leinster.text and read its content.\"}\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create (\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    temperature=0,\n",
    "    tools=[pydantic_function_tool(ReadFileTool)]\n",
    "    )\n",
    "\n",
    " # read the file\n",
    "    tool_name = response.choices[0].message.tool_calls[0].function.name\n",
    "    tool_args = json.loads(response.choices[0].message.tool_calls[0].function.arguments)\n",
    "    print(tool_args)\n",
    "    file_content = ReadFileTool(**tool_args).run()\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a useful assistant that summarises text.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Please summarise the following text: {content}\".format(content=file_content)}\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create (\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    temperature=0,\n",
    "    tools=[pydantic_function_tool(ReadFileTool)]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c1627c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'leinster.text'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Leinster Rugby is one of Ireland's four professional rugby union teams, competing in the United Rugby Championship and European Rugby Champions Cup. They play their home games at the RDS Arena in Dublin, with larger matches held at Aviva Stadium. Founded in 1995, Leinster has been highly successful, winning nine domestic titles and four European Champions Cups. They are known for their blue jerseys and a crest featuring a harp.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarise_workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bd76a09",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# write function to execute tool. Take function name and parameters and return result of function\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;129m@traceable\u001b[39m(name=\u001b[33m\"\u001b[39m\u001b[33mAD Tool Call\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute_function\u001b[39m(tool_call, tool_lookup):\n\u001b[32m      4\u001b[39m     function_name = tool_call.function.name\n\u001b[32m      5\u001b[39m     args = json.loads(tool_call.function.arguments)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<stringsource>:69\u001b[39m, in \u001b[36mcfunc.to_py.__Pyx_CFunc_b0409f__29_pydevd_sys_monitoring_cython_object__lParen__etc_to_py_4code_4line.wrap\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1481\u001b[39m, in \u001b[36m_pydevd_sys_monitoring_cython._line_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1523\u001b[39m, in \u001b[36m_pydevd_sys_monitoring_cython._internal_line_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1324\u001b[39m, in \u001b[36m_pydevd_sys_monitoring_cython._stop_on_breakpoint\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1961\u001b[39m, in \u001b[36m_pydevd_sys_monitoring_cython._do_wait_suspend\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Foundations_of_AgenticAI/agentic-labs/.venv/lib/python3.12/site-packages/debugpy/_vendored/pydevd/pydevd.py:2188\u001b[39m, in \u001b[36mPyDB.do_wait_suspend\u001b[39m\u001b[34m(self, thread, frame, event, arg, exception_type)\u001b[39m\n\u001b[32m   2185\u001b[39m             from_this_thread.append(frame_custom_thread_id)\n\u001b[32m   2187\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._threads_suspended_single_notification.notify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[32m-> \u001b[39m\u001b[32m2188\u001b[39m         keep_suspended = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2190\u001b[39m frames_list = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[32m   2193\u001b[39m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Foundations_of_AgenticAI/agentic-labs/.venv/lib/python3.12/site-packages/debugpy/_vendored/pydevd/pydevd.py:2257\u001b[39m, in \u001b[36mPyDB._do_wait_suspend\u001b[39m\u001b[34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[39m\n\u001b[32m   2254\u001b[39m                 queue.put(internal_cmd)\n\u001b[32m   2255\u001b[39m                 wait_timeout = TIMEOUT_FAST\n\u001b[32m-> \u001b[39m\u001b[32m2257\u001b[39m         \u001b[43mnotify_event\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2258\u001b[39m         notify_event.clear()\n\u001b[32m   2260\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/threading.py:655\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    653\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    361\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# write function to execute tool. Take function name and parameters and return result of function\n",
    "@traceable(name=\"AD Tool Call\")\n",
    "def execute_function(tool_call, tool_lookup):\n",
    "    function_name = tool_call.function.name\n",
    "    args = json.loads(tool_call.function.arguments)\n",
    "    tool = tool_lookup[function_name](**args)\n",
    "    return function_name, tool.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31355add",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(name=\"react_loop\")\n",
    "def react_loop(messages, client, tools):\n",
    "        tool_lookup = {tool.__name__: tool for tool in tools}\n",
    "        tool_schemas = [pydantic_function_tool(tool) for tool in tools]\n",
    "        while True:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                temperature=0,\n",
    "                tools=tool_schemas\n",
    "            )\n",
    "            # get the tool calls from the response\n",
    "            tools_to_run = response.choices[0].message.tool_calls\n",
    "            if not tools_to_run:\n",
    "                #messages.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content})\n",
    "                break\n",
    "\n",
    "            # execute the tool calls\n",
    "            for tool_call in tools_to_run:\n",
    "                function_name, tool_response = execute_function(tool_call, tool_lookup)\n",
    "                print(f\"executing {function_name}, \\n tool response : \\n {tool_response} \")\n",
    "                # messages.append({\"role\": \"assistant\", \"content\": None, \"function_call\" : tool_call})\n",
    "                #messages.append({\"role\": \"function\", \"name\": function_name, \"content\": tool_response})\n",
    "\n",
    "            return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39a83bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a useful text files assistant that can locate text files in a given directory path, reads text files, merges their contents.\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Find text files in directory /home/aidodo/Foundations_of_AgenticAI/agentic-labs, then merge their contents of the returned list\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e91a95fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [FindTextFilesAndMergeSummarise]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2f5b77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing FindTextFilesAndMergeSummarise, \n",
      " tool response : \n",
      " The provided text contains information about two distinct subjects:\n",
      "\n",
      "**Tom Hanks:** He is a highly acclaimed American actor and filmmaker, recognized globally for his diverse roles and cultural impact. Hanks has received numerous prestigious awards, including two Academy Awards, and is known for his collaborations with directors like Steven Spielberg.\n",
      "\n",
      "**Leinster Rugby:** This is one of Ireland's four professional rugby union teams, competing in the United Rugby Championship and European Rugby Champions Cup. They primarily play at the RDS Arena in Dublin and have been a highly successful team, particularly in their domestic league and European competitions. \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "response = react_loop(messages, client, tools)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4ff472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(name=\"Summarise List Workflow\")\n",
    "def summarise_list_workflow():\n",
    "\n",
    " # message to read file\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a useful text files assistant that can locate text files in a given directory path and Merge their contents\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Find text files in directory /home/aidodo/Foundations_of_AgenticAI/agentic-labs and merge their contents.\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create (\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    temperature=0,\n",
    "    tools=[pydantic_function_tool(FindTextFilesAndMerge)]\n",
    "    )\n",
    "\n",
    " # read the file\n",
    "    #tool_name = response.choices[0].message.tool_calls[0].function.name\n",
    "    tool_args = json.loads(response.choices[0].message.tool_calls[0].function.arguments)\n",
    "    merged_content = FindTextFilesAndMerge(**tool_args).run()\n",
    "    #print(f\"Printing File List \\n##############\\n {file_content}\" )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a useful assistant that summarises text.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Please summarise the following text: {content}\".format(content=merged_content)}\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create (\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        tools=[pydantic_function_tool(FindTextFilesAndMerge)]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56e56ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The provided text contains information about two distinct entities: Tom Hanks and Leinster Rugby.\\n\\nTom Hanks is a highly acclaimed American actor and filmmaker, recognized globally as a cultural icon. He is known for his versatile roles in both comedy and drama, and is one of the highest-grossing actors in the US. Hanks has received numerous awards, including two Academy Awards, and has a notable history of collaborations with directors like Steven Spielberg, Ron Howard, Nora Ephron, and Robert Zemeckis.\\n\\nLeinster Rugby is one of Ireland's four professional rugby union teams, competing in the United Rugby Championship and the European Rugby Champions Cup. They primarily play at the RDS Arena in Dublin, with larger matches held at Aviva Stadium. Leinster has been a dominant force in Irish and European rugby since turning professional in 1995, having won multiple domestic titles and four European Champions Cups.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarise_list_workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29de6542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e96bea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eae710b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6a1451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba488b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16dc99a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318009a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfe134f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc9d13e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d891769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c820b93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9f26a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-labs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
