{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb08c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9f87dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('crm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29603867",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['System'] == 'PGW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2932ec22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all values in 'Subject' column to lowercase\n",
    "df['Subject'] = df['Subject'].str.lower()\n",
    "\n",
    "print(\"Subject column after converting to lowercase:\")\n",
    "print(df['Subject'].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d48a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all instances of 'samsung' from the 'Subject' column\n",
    "df['Subject'] = df['Subject'].str.replace('samsung', '', regex=False)\n",
    "\n",
    "print(\"Subject column after removing 'samsung':\")\n",
    "print(df['Subject'].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aaa904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace substrings 'sae', 'saegw', 'saes', 'sae-gw', 'saeegws' with 'pgw'\n",
    "substrings_to_replace = ['sae', 'saegw', 'saes', 'sae-gw', 'saegws']\n",
    "\n",
    "for substring in substrings_to_replace:\n",
    "    df['Subject'] = df['Subject'].str.replace(substring, 'pgw', regex=False)\n",
    "\n",
    "print(\"Subject column after replacing substrings:\")\n",
    "print(df['Subject'].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df083b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all instances of 'samsung' from the 'Subject' column\n",
    "df['Subject'] = df['Subject'].str.replace('pgwgw', 'pgw', regex=False)\n",
    "\n",
    "print(\"Subject column after removing 'samsung':\")\n",
    "print(df['Subject'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bd79fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('PGW_crm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce57a71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize any word containing 'pgw' to exactly 'pgw' in the 'Subject' column\n",
    "# Ensure Subject is string\n",
    "df['Subject'] = df['Subject'].astype(str)\n",
    "\n",
    "# Replace any word that contains 'pgw' with 'pgw'\n",
    "df['Subject'] = df['Subject'].str.replace(r\"\\b\\w*pgw\\w*\\b\", 'pgw', regex=True)\n",
    "\n",
    "# Collapse multiple spaces and trim\n",
    "df['Subject'] = df['Subject'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "print(\"Subject column after normalizing 'pgw' words (sample 20):\")\n",
    "print(df['Subject'].head(20).to_string(index=False))\n",
    "\n",
    "# Optional: show count of rows that now contain 'pgw'\n",
    "pgw_count = df['Subject'].str.contains(r\"\\bpgw\\b\").sum()\n",
    "print(f\"\\nRows containing 'pgw': {pgw_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f333c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5aeed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# Ensure Subject is string\n",
    "df['Subject'] = df['Subject'].astype(str)\n",
    "\n",
    "# Remove all punctuation characters using str.translate and string.punctuation\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "df['Subject'] = df['Subject'].str.translate(translator)\n",
    "\n",
    "# Collapse multiple spaces and trim\n",
    "df['Subject'] = df['Subject'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "print(\"Subject column after removing punctuation (sample 20):\")\n",
    "print(df['Subject'].head(20).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e403b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand contractions in the 'Subject' column using the `contractions` package\n",
    "# This cell will try to import contractions and install it if missing.\n",
    "import contractions\n",
    "\n",
    "\n",
    "# Ensure Subject is string-typed\n",
    "df['Subject'] = df['Subject'].astype(str)\n",
    "\n",
    "# Apply expansion\n",
    "df['Subject'] = df['Subject'].apply(lambda s: contractions.fix(s))\n",
    "\n",
    "# Collapse extra spaces and trim\n",
    "df['Subject'] = df['Subject'].str.replace(r\"\\s+\", ' ', regex=True).str.strip()\n",
    "\n",
    "print(\"Sample of 'Subject' after expanding contractions:\")\n",
    "print(df['Subject'].head(20).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5212df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spell-check Subject column using pyspellchecker\n",
    "# Installs pyspellchecker if missing, then finds misspelled words per row.\n",
    "import re\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()\n",
    "\n",
    "def find_misspellings(s):\n",
    "    if not isinstance(s, str) or not s.strip():\n",
    "        return []\n",
    "    # extract words (keep apostrophes inside words)\n",
    "    words = re.findall(r\"[A-Za-z']+\", s)\n",
    "    # lowercase and filter short tokens\n",
    "    words = [w.lower() for w in words if len(w) > 1]\n",
    "    if not words:\n",
    "        return []\n",
    "    miss = spell.unknown(words)\n",
    "    return sorted(miss)\n",
    "\n",
    "# Apply\n",
    "df['subject_misspellings'] = df['Subject'].apply(find_misspellings)\n",
    "\n",
    "# Summary\n",
    "from collections import Counter\n",
    "all_miss = [w for lst in df['subject_misspellings'] for w in lst]\n",
    "miss_counts = Counter(all_miss)\n",
    "\n",
    "print('Total rows checked:', len(df))\n",
    "print('Rows with >=1 misspelling:', (df['subject_misspellings'].str.len() > 0).sum())\n",
    "print('\\nTop misspelled tokens (up to 50):')\n",
    "for w,c in miss_counts.most_common(50):\n",
    "    print(f\"{w}: {c}\")\n",
    "\n",
    "# Show sample rows with misspellings\n",
    "print('\\nSample rows with misspellings (first 20):')\n",
    "rows = df[df['subject_misspellings'].str.len() > 0]\n",
    "for idx, row in rows.head(20).iterrows():\n",
    "    print('---')\n",
    "    print('Index:', idx)\n",
    "    print('Subject:', row['Subject'])\n",
    "    print('Misspellings:', row['subject_misspellings'])\n",
    "\n",
    "# Keep the column for further inspection\n",
    "print('\\nAdded column: subject_misspellings')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd79601f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772e60e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive spelling correction for `df['Subject']`\n",
    "# Prompts you to accept a suggested correction, skip, or enter a custom replacement.\n",
    "# Runs in a notebook cell (expects interactive input()).\n",
    "import re\n",
    "from spellchecker import SpellChecker\n",
    "spell = SpellChecker()\n",
    "\n",
    "# Helper to find candidate misspellings for a single subject\n",
    "word_re = re.compile(r\"[A-Za-z']+\")\n",
    "\n",
    "def words_from_text(s):\n",
    "    return [w for w in re.findall(word_re, s)]\n",
    "\n",
    "# Ensure Subject is string\n",
    "df['Subject'] = df['Subject'].astype(str)\n",
    "\n",
    "# Iterate rows and prompt for corrections\n",
    "print('Interactive spelling correction starting. For each misspelled token you will be prompted.')\n",
    "print(\"Instructions: press Enter to accept suggested correction, type 's' to skip, type 'r' to provide replacement.\")\n",
    "\n",
    "rows_with_issues = []\n",
    "for idx, row in df.iterrows():\n",
    "    subj = row['Subject']\n",
    "    words = words_from_text(subj)\n",
    "    # lowercase words for spellchecking but keep original for replacements\n",
    "    candidates = [w for w in words if len(w) > 1]\n",
    "    if not candidates:\n",
    "        continue\n",
    "    miss = spell.unknown([w.lower() for w in candidates])\n",
    "    if not miss:\n",
    "        continue\n",
    "\n",
    "    # We have misspellings in this row\n",
    "    changed = False\n",
    "    subj_new = subj\n",
    "    print('\\n' + '='*60)\n",
    "    print(f'Row index: {idx}')\n",
    "    print('Original Subject:')\n",
    "    print(subj)\n",
    "\n",
    "    for w in sorted(set(candidates), key=lambda x: x.lower()):\n",
    "        w_l = w.lower()\n",
    "        if w_l not in miss:\n",
    "            continue\n",
    "        suggestion = spell.correction(w_l) or w\n",
    "        suggestions = spell.candidates(w_l)\n",
    "        print('\\nMisspelled token: \"' + w + '\"')\n",
    "        print('Suggested correction:', suggestion)\n",
    "        if suggestions:\n",
    "            print('Other candidates:', ', '.join(sorted(suggestions)))\n",
    "        print('Context:')\n",
    "        # show short context around the token\n",
    "        context = re.sub(r\"\\b\" + re.escape(w) + r\"\\b\", f\">>{w}<<\", subj)\n",
    "        print(context)\n",
    "\n",
    "        resp = input(\"Action ([Enter]=accept, s=skip, r=replace): \").strip()\n",
    "        if resp == 's':\n",
    "            print('Skipped')\n",
    "            continue\n",
    "        elif resp == 'r':\n",
    "            repl = input('Enter replacement: ').strip()\n",
    "            if not repl:\n",
    "                print('Empty replacement, skipped')\n",
    "                continue\n",
    "            replacement = repl\n",
    "        else:\n",
    "            # default accept suggestion\n",
    "            replacement = suggestion\n",
    "\n",
    "        # Replace whole-word occurrences of the token (case-sensitive replacement preserving case as best effort)\n",
    "        # We'll replace exact matches of the token (case-sensitive) and also lowercase matches\n",
    "        subj_new = re.sub(r\"\\b\" + re.escape(w) + r\"\\b\", replacement, subj_new)\n",
    "        subj_new = re.sub(r\"\\b\" + re.escape(w_l) + r\"\\b\", replacement, subj_new, flags=re.IGNORECASE)\n",
    "        changed = True\n",
    "        print(f'Applied replacement: {replacement}')\n",
    "\n",
    "    if changed:\n",
    "        print('Updated Subject:')\n",
    "        print(subj_new)\n",
    "        apply_resp = input('Apply these changes to this row? (y/N): ').strip().lower()\n",
    "        if apply_resp == 'y':\n",
    "            df.at[idx, 'Subject'] = subj_new\n",
    "            rows_with_issues.append(idx)\n",
    "            print('Change applied.')\n",
    "        else:\n",
    "            print('Change discarded.')\n",
    "\n",
    "            \n",
    "\n",
    "print('\\nInteractive correction finished.')\n",
    "print(f'Rows updated: {len(rows_with_issues)}')\n",
    "print('You may want to save the notebook to persist df changes.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ad38a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('PGW_crm.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e27c4ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66ca592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove English stopwords from `Subject` using NLTK\n",
    "# Installs NLTK if missing, downloads stopwords, and strips stopwords from each Subject.\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# Ensure stopwords are downloaded\n",
    "nltk.download('stopwords', quiet=True)\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "# Helper to remove stopwords while preserving words\n",
    "word_re = re.compile(r\"\\w+\")\n",
    "\n",
    "def remove_stopwords_subject(s):\n",
    "    if not isinstance(s, str) or not s.strip():\n",
    "        return s\n",
    "    tokens = word_re.findall(s)\n",
    "    filtered = [t for t in tokens if t.lower() not in stop]\n",
    "    return ' '.join(filtered)\n",
    "\n",
    "# Ensure Subject is string\n",
    "df['Subject'] = df['Subject'].astype(str)\n",
    "# Apply removal\n",
    "original_nonempty = (df['Subject'].str.strip() != '').sum()\n",
    "df['Subject'] = df['Subject'].apply(remove_stopwords_subject)\n",
    "\n",
    "print(f\"Applied stopword removal to {original_nonempty} non-empty Subject rows.\")\n",
    "print('Sample after stopword removal:')\n",
    "print(df['Subject'].head(20).to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-labs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
