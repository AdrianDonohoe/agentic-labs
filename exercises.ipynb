{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39731276",
   "metadata": {},
   "source": [
    "### Exercise 2 : Create a program to ask a model to list all European countries, with their capital city. Create Pydantic classes torepresent the structure of the required response (one class representing a City and one the collection of cities)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5e302e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f30418b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from langsmith.wrappers import wrap_openai\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import pydantic_function_tool\n",
    "from langsmith import traceable\n",
    "load_dotenv()\n",
    "\n",
    "# read in env variables\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "api_base = os.getenv(\"GEMINI_API_BASE\")\n",
    "model = os.getenv(\"GEMINI_API_MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0f8ef7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = wrap_openai(OpenAI(\n",
    " api_key=api_key,\n",
    " base_url=api_base,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e24fc6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data model for the math reasoning steps\n",
    "class City(BaseModel):\n",
    "    name: str = Field(description=\"The name of the city\")\n",
    "    country: str = Field(description=\"The country where the city is located\")\n",
    "\n",
    "# Define the data model for the overall math reasoning\n",
    "class EuroCities(BaseModel):\n",
    "    steps: list[City]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "497fc69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.parse(\n",
    "    model=model,\n",
    "    messages=[\n",
    "\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Provide a list of all European Captial Cities.\"\n",
    "        }\n",
    "    ],\n",
    "    response_format=EuroCities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e5043d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: Albania\n",
      "Capital: Tirana\n",
      "\n",
      "Country: Andorra\n",
      "Capital: Andorra la Vella\n",
      "\n",
      "Country: Austria\n",
      "Capital: Vienna\n",
      "\n",
      "Country: Belarus\n",
      "Capital: Minsk\n",
      "\n",
      "Country: Belgium\n",
      "Capital: Brussels\n",
      "\n",
      "Country: Bosnia and Herzegovina\n",
      "Capital: Sarajevo\n",
      "\n",
      "Country: Bulgaria\n",
      "Capital: Sofia\n",
      "\n",
      "Country: Croatia\n",
      "Capital: Zagreb\n",
      "\n",
      "Country: Cyprus\n",
      "Capital: Nicosia\n",
      "\n",
      "Country: Czech Republic\n",
      "Capital: Prague\n",
      "\n",
      "Country: Denmark\n",
      "Capital: Copenhagen\n",
      "\n",
      "Country: Estonia\n",
      "Capital: Tallinn\n",
      "\n",
      "Country: Finland\n",
      "Capital: Helsinki\n",
      "\n",
      "Country: France\n",
      "Capital: Paris\n",
      "\n",
      "Country: Germany\n",
      "Capital: Berlin\n",
      "\n",
      "Country: Greece\n",
      "Capital: Athens\n",
      "\n",
      "Country: Hungary\n",
      "Capital: Budapest\n",
      "\n",
      "Country: Iceland\n",
      "Capital: Reykjavik\n",
      "\n",
      "Country: Ireland\n",
      "Capital: Dublin\n",
      "\n",
      "Country: Italy\n",
      "Capital: Rome\n",
      "\n",
      "Country: Kosovo\n",
      "Capital: Pristina\n",
      "\n",
      "Country: Latvia\n",
      "Capital: Riga\n",
      "\n",
      "Country: Liechtenstein\n",
      "Capital: Vaduz\n",
      "\n",
      "Country: Lithuania\n",
      "Capital: Vilnius\n",
      "\n",
      "Country: Luxembourg\n",
      "Capital: Luxembourg City\n",
      "\n",
      "Country: North Macedonia\n",
      "Capital: Skopje\n",
      "\n",
      "Country: Malta\n",
      "Capital: Valletta\n",
      "\n",
      "Country: Moldova\n",
      "Capital: Chisinau\n",
      "\n",
      "Country: Monaco\n",
      "Capital: Monaco\n",
      "\n",
      "Country: Montenegro\n",
      "Capital: Podgorica\n",
      "\n",
      "Country: Netherlands\n",
      "Capital: Amsterdam\n",
      "\n",
      "Country: Norway\n",
      "Capital: Oslo\n",
      "\n",
      "Country: Poland\n",
      "Capital: Warsaw\n",
      "\n",
      "Country: Portugal\n",
      "Capital: Lisbon\n",
      "\n",
      "Country: Romania\n",
      "Capital: Bucharest\n",
      "\n",
      "Country: Russia\n",
      "Capital: Moscow\n",
      "\n",
      "Country: San Marino\n",
      "Capital: San Marino\n",
      "\n",
      "Country: Serbia\n",
      "Capital: Belgrade\n",
      "\n",
      "Country: Slovakia\n",
      "Capital: Bratislava\n",
      "\n",
      "Country: Slovenia\n",
      "Capital: Ljubljana\n",
      "\n",
      "Country: Spain\n",
      "Capital: Madrid\n",
      "\n",
      "Country: Sweden\n",
      "Capital: Stockholm\n",
      "\n",
      "Country: Switzerland\n",
      "Capital: Bern\n",
      "\n",
      "Country: Turkey\n",
      "Capital: Ankara\n",
      "\n",
      "Country: Ukraine\n",
      "Capital: Kyiv\n",
      "\n",
      "Country: United Kingdom\n",
      "Capital: London\n",
      "\n",
      "Country: Vatican City\n",
      "Capital: Vatican City\n",
      "\n"
     ]
    }
   ],
   "source": [
    "solution = response.choices[0].message.parsed\n",
    "\n",
    " # Print the final answer\n",
    "for step in solution.steps:\n",
    "    print(f\"Country: {step.country}\")\n",
    "    print(f\"Capital: {step.name}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588775e8",
   "metadata": {},
   "source": [
    "### In the following exercise you will create a tool to read the content of a file and summarise it.\n",
    "a.\n",
    "Start by creating a tool which returns the content of a filename found in the current working directory (usePydantic to define the tool). Then send a request to the model to summarise the content of a named file, alsopassing the tool definition you created. Check the response contains the tool name and the name of the file as anargument.\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "b.\n",
    "Write a function that takes the tool name and arguments returned from the LM call, and execute the function(should return the content of a file).\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "c.\n",
    "From Q4, add the file content to the message context (as an assistant message). To ensure best results makesure it is clear that the text is the text of the requested file (e.g. filename=”….”). Now call the model again with theappended context and observe the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8930bc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'function', 'function': {'name': 'getFileContent', 'strict': True, 'parameters': {'description': 'Return  tool for getting file content.', 'properties': {'filename': {'description': 'the name of the file found in current working directory', 'title': 'Filename', 'type': 'string'}}, 'required': ['filename'], 'title': 'getFileContent', 'type': 'object', 'additionalProperties': False}, 'description': 'Return  tool for getting file content.'}}\n"
     ]
    }
   ],
   "source": [
    "class getFileContent(BaseModel):\n",
    "    \"\"\"Return  tool for getting file content.\"\"\"\n",
    "    filename: str = Field(description=\"the name of the file found in current working directory\")\n",
    "    \n",
    "\n",
    "    def getFileContent(self):\n",
    "        with open(self.filename, \"r\") as f:\n",
    "            content = f.read()\n",
    "        return content\n",
    "\n",
    "\n",
    "tool = pydantic_function_tool(getFileContent)\n",
    "\n",
    "print(tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3861c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"content of file 'test.txt\"}]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    messages=messages,\n",
    "    tools=tool\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f17bb85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getFileContent\n",
      "{\"filename\":\"test.txt\"}\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.tool_calls[0].function.name)\n",
    "print(response.choices[0].message.tool_calls[0].function.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44b2bf3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Function(arguments='{\"filename\":\"test.txt\"}', name='getFileContent')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_call = response.choices[0].message.tool_calls[0].function\n",
    "function_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cfedc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"filename\":\"test.txt\"}\n"
     ]
    }
   ],
   "source": [
    "tool_lookup = {\"content\" : getFileContent}\n",
    "#print(tool_lookup['content'])\n",
    "args = function_call.arguments\n",
    "print(args)\n",
    "#res = getFileContent.getFileContent(**args)\n",
    "#res = tool_lookup['content'](**args).getFileContent()\n",
    "#print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8499a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ast.literal_eval(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec51f96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = getFileContent(**args).getFileContent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07bedc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file 'test.txt' contains a biography of Thomas Jeffrey Hanks, an American actor and filmmaker born on July 9, 1956. He is recognized for his versatile roles in both comedy and drama, and is considered a global film star and American cultural icon. Hanks has received numerous awards, including two Academy Awards, seven Emmy Awards, and four Golden Globe Awards. He gained initial fame through comedy films like *Splash* and *Big*, and later won two consecutive Best Actor Academy Awards for his roles in *Philadelphia* and *Forrest Gump*. He has a notable collaborative history with director Steven Spielberg, working on films such as *Saving Private Ryan* and miniseries like *Band of Brothers*.\n",
      "[{'role': 'system', 'content': 'You are a helpful tutor.'}, {'role': 'user', 'content': \"content of file 'test.txt'\"}, {'role': 'assistant', 'content': 'This is the contents of the requested file test.txt: Thomas Jeffrey Hanks (born July 9, 1956) is an American actor and filmmaker. Known for both his comedic and dramatic roles, he is one of the most popular and recognizable film stars worldwide, and is regarded as an American cultural icon.[2] Hanks is ranked as the fourth-highest-grossing American film actor.[3][4] His numerous awards include two Academy Awards, seven Emmy Awards, and four Golden Globe Awards; he has also been nominated for five BAFTA Awards and a Tony Award. He received the AFI Life Achievement Award in 2002, the Kennedy Center Honor in 2014, the Presidential Medal of Freedom in 2016, and the Golden Globe Cecil B. DeMille Award in 2020.[5][6][7]\\n\\nHanks rose to fame with leading roles in comedies Splash (1984), The Money Pit (1986), Big (1988), and A League of Their Own (1992). He won two consecutive Academy Awards for Best Actor, playing a gay lawyer suffering from AIDS in Philadelphia (1993), then the title character in Forrest Gump (1994).[8] Hanks has collaborated with Steven Spielberg on five films—Saving Private Ryan (1998), Catch Me If You Can (2002), The Terminal (2004), Bridge of Spies (2015), and The Post (2017)—and three World War II-themed miniseries: Band of Brothers (2001), The Pacific (2010), and Masters of the Air (2024). He has also frequently collaborated with directors Ron Howard, Nora Ephron, and Robert Zemeckis.'}, {'role': 'user', 'content': \"summarize content of file 'test.txt'\"}, {'role': 'assistant', 'content': \"The file 'test.txt' contains a biography of Thomas Jeffrey Hanks, an American actor and filmmaker born on July 9, 1956. He is recognized for his versatile roles in both comedy and drama, and is considered a global film star and American cultural icon. Hanks has received numerous awards, including two Academy Awards, seven Emmy Awards, and four Golden Globe Awards. He gained initial fame through comedy films like *Splash* and *Big*, and later won two consecutive Best Actor Academy Awards for his roles in *Philadelphia* and *Forrest Gump*. He has a notable collaborative history with director Steven Spielberg, working on films such as *Saving Private Ryan* and miniseries like *Band of Brothers*.\"}]\n"
     ]
    }
   ],
   "source": [
    "@traceable(name=\"multi_turn_conversation\")\n",
    "def multi_turn_conversation():\n",
    "    \"\"\"Demonstrate multi-turn conversation with context preservation\"\"\"\n",
    "\n",
    "    # Initialize conversation history with the system message\n",
    "    conversation_history = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful tutor.\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # now add the first user message to the history\n",
    "    conversation_history.append(\n",
    "        {\"role\": \"user\", \"content\": \"content of file 'test.txt'\"})\n",
    "\n",
    "    # now call the model to get the assistant's response\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=conversation_history,\n",
    "        temperature=0.1,\n",
    "        tools=tool\n",
    "    )\n",
    "    function_call = response.choices[0].message.tool_calls[0].function\n",
    "    tool_lookup = {\"content\" : getFileContent}\n",
    "    #print(tool_lookup['content'])\n",
    "    args = function_call.arguments\n",
    "    args = ast.literal_eval(args)\n",
    "    res = getFileContent(**args).getFileContent()\n",
    "    res = 'This is the contents of the requested file test.txt: ' + res\n",
    "\n",
    "    # add the response to the conversation history\n",
    "    assistant_response = response.choices[0].message.content\n",
    "    conversation_history.append({\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": res\n",
    "    })\n",
    "\n",
    "    # now ask a follow-up question\n",
    "    conversation_history.append(\n",
    "        {\"role\": \"user\", \"content\": \"summarize content of file 'test.txt'\"})\n",
    "\n",
    "    # now call the model to get the assistant's response\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=conversation_history,\n",
    "        temperature=0.1,\n",
    "        tools=tool\n",
    "    )\n",
    "    assistant_response = response.choices[0].message.content\n",
    "    conversation_history.append({\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": assistant_response\n",
    "    })\n",
    "    print(assistant_response)\n",
    "    '''\n",
    "    conversation_history.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"How do I add items to it?\"\n",
    "    })\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=conversation_history,\n",
    "        temperature=0.1\n",
    "    )\n",
    "\n",
    "    # now add the assistant's response to the history\n",
    "    assistant_response = response.choices[0].message.content\n",
    "    conversation_history.append({\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": assistant_response\n",
    "    })\n",
    "\n",
    "    # ask another follow-up question\n",
    "    conversation_history.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the difference between append() and extend()?\"\n",
    "    })\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=conversation_history,\n",
    "        temperature=0.1\n",
    "    )\n",
    "\n",
    "    assistant_response = response.choices[0].message.content\n",
    "    print\n",
    "    conversation_history.append({\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": assistant_response\n",
    "    })\n",
    "    '''\n",
    "\n",
    "    return conversation_history\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(multi_turn_conversation())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-labs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
